---
title: 【爬虫】豆瓣排行、三国演义小说
tags:
 - python
 - 爬虫
---
爬下豆瓣电影排行榜的前250名保存到excel中
```py
import pandas as pd
from bs4 import BeautifulSoup
import os

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'
}//浏览器标识
movie_list = []
for i in range(10):  # 爬1-10页
    ul = 'https://movie.douban.com/top250?start=' + str(i * 25) + '&filter='
    html = requests.get(ul, headers=headers).text
    soup = BeautifulSoup(html, "lxml")
    div_list = soup.find_all('div', {'class': 'info'})
    for node in div_list:
        title = node.find('a').find('span').text
        score = node.find('div', {'class': 'star'}).find('span', {'class': 'rating_num'}).text + '分'
        link = node.find('a')['href']
        data_dict = {'电影': title, '评分': score, '链接': link}
        movie_list.append(data_dict)
movie = pd.DataFrame(movie_list)
print(movie)
movie.to_excel('E:\\360Downloads')
```
将网站中的三国演义小说爬下来保存。
![2020-04-02-3](https://user-images.githubusercontent.com/48319720/78244554-6b6a1280-7518-11ea-9851-c600304bec15.png)

```py
import requests
import pandas as pd
from bs4 import BeautifulSoup
import os
headers = {
    'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'
}

for i in range(1,121):
    ul = 'http://www.shicimingju.com/book/sanguoyanyi/'+str(i)+'.html'
    html = requests.get(ul, headers=headers).text
    soup = BeautifulSoup(html, "lxml")
    div = soup.find_all('div',{'class': 'card bookmark-list'})
    title = div[0].find('h1').text
    soup = BeautifulSoup(div[0].text, "lxml")
    artical = soup.find_all('p')[0].text
    fileOb = open('E:\\360Downloads\\three\\'+str(title)+'.txt','w',encoding='utf-8')
    fileOb.write(artical)
    fileOb.close()
```